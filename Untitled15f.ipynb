{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15f.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMGNeOYt84n0WLK+9TlG+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumiyamoon05/TechBD/blob/main/Untitled15f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-E3pgfy-ZQc"
      },
      "outputs": [],
      "source": [
        "#KNN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#2\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#3\n",
        "df= pd.read_csv('')\n",
        "#4\n",
        "df\n",
        "#5\n",
        "df.head()\n",
        "#6\n",
        "df.tail()\n",
        "#7\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, 4].values\n",
        "#8\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "#9\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "#10\n",
        "#import knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)\n",
        "#11\n",
        "y_pred = classifier.predict(X_test)\n",
        "#12\n",
        "#confution matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#13\n",
        "error = []\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test\n",
        "#14\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')\n",
        "\n",
        "#END knn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decision tree & gini\n",
        "import pandas as pd\n",
        "df = pd.read_csv('gender_classification.csv')\n",
        "#2\n",
        "data = df.copy()\n",
        "data.head()\n",
        "#3\n",
        "x = data.iloc[:, :-1]\n",
        "y = data.iloc[:, 7]\n",
        "print(x, y)\n",
        "#4\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, x_test, Y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
        "print(X_train, x_test, Y_train, y_test)\n",
        "#5\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
        "clf_gini.fit(X_train, Y_train)\n",
        "#6\n",
        "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
        "clf_en.fit(X_train, Y_train)\n",
        "#7\n",
        "y_pred_en = clf_en.predict(x_test)\n",
        "#7\n",
        "y_pred_gini = clf_gini.predict(x_test)\n",
        "#8\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))\n",
        "#9\n",
        "print('Model accuracy score with criterion entropy index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))\n",
        "#10\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred_gini)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "#11\n",
        "cm_en = confusion_matrix(y_test, y_pred_en)\n",
        "print('Confusion matrix with citerion entropy\\n\\n', cm_en)\n",
        "#12\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_gini))\n",
        "#13\n",
        "print(classification_report(y_test, y_pred_en))\n",
        "#14\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(24,16))\n",
        "from sklearn import tree\n",
        "tree.plot_tree(clf_en.fit(X_train, Y_train)) \n",
        "#15\n",
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf_en, out_file=None, \n",
        "                              feature_names=X_train.columns,  \n",
        "                              class_names=Y_train,  \n",
        "                              filled=True, rounded=True,  \n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data) \n",
        "graph\n",
        "\n",
        "#End df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "-ex9tB-NHrtQ",
        "outputId": "f80ba5af-93ec-4383-f042-eaccc6b8d235"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-39f0d896fe82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#decision tree & gini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gender_classification.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gender_classification.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression\n",
        "#1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#2\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#3\n",
        "df = pd.read_csv('bottle.csv')\n",
        "df_binary = df[['Salnty', 'T_degC']]\n",
        "df_binary.columns = ['Sal', 'Temp'] # Taking only the selected two attributes from the dataset\n",
        "df_binary.head() #display the first 5 rows\n",
        "#4\n",
        "sns.lmplot(x =\"Sal\", y =\"Temp\", data = df_binary, order = 2, ci = None)\n",
        "#5\n",
        "df_binary.fillna(method ='ffill', inplace = True)\n",
        "#6\n",
        "X = np.array(df_binary['Sal']).reshape(-1, 1)\n",
        "y = np.array(df_binary['Temp']).reshape(-1, 1)\n",
        "df_binary.dropna(inplace = True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train, y_train)\n",
        "print(regr.score(X_test, y_test))\n",
        "#7\n",
        "y_pred = regr.predict(X_test)\n",
        "plt.scatter(X_test, y_test, color ='b')\n",
        "plt.plot(X_test, y_pred, color ='k')\n",
        "plt.show()\n",
        "#8\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
        "#squared True returns MSE value, False returns RMSE value.\n",
        "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
        "rmse = mean_squared_error(y_true=y_test,y_pred=y_pred,squared=False)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "#end reee\n",
        "\n",
        "#1 new data upld\n",
        "import pandas as pd\n",
        "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree',\n",
        "'age', 'label']\n",
        "# load dataset\n",
        "pima = pd.read_csv(\"diabetes.csv\", header=None, names=col_names)\n",
        "pima.head()\n",
        "#2\n",
        "#split dataset in features and target variable\n",
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "X = pima[feature_cols] # Features\n",
        "y = pima.label # Target variable\n",
        "#3\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state\n",
        "=0)\n",
        "#4\n",
        "from sklearn.linear_model import LogisticRegression\n",
        " # instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression()\n",
        "# fit the model with data\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred=logreg.predict(X_test)\n",
        "#5\n",
        "from sklearn import metrics\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix\n",
        "#6\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "class_names=[0,1] # name of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "#7\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "36mvtx6sFO4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aprior\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "#2\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "#3\n",
        "df = pd.read_excel('Online Retail.xlsx')\n",
        "df.head()\n",
        "#4\n",
        "df['Description'] = df['Description'].str.strip()\n",
        "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
        "df = df[~df['InvoiceNo'].str.contains('C')]\n",
        "df\n",
        "#5\n",
        "basket = (df[df['Country'] ==\"France\"]\n",
        "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
        "          .sum().unstack().reset_index().fillna(0)\n",
        "          .set_index('InvoiceNo'))\n",
        "basket\n",
        "#6\n",
        "def encode_units(x):\n",
        "    if x <= 0:\n",
        "        return 0\n",
        "    if x >= 1:\n",
        "        return 1\n",
        "basket_sets = basket.applymap(encode_units)\n",
        "basket_sets.drop('POSTAGE', inplace=True, axis=1)\n",
        "basket_sets\n",
        "#7\n",
        "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "rules.head()\n",
        "#8\n",
        "rules[ (rules['lift'] >= 6) &\n",
        "      (rules['confidence'] >= 0.8) ]\n",
        "#9\n",
        "#for uk\n",
        "data=df[df.Country=='United Kingdom'].groupby(['InvoiceNo', 'Description'])['Quantity'].sum()\n",
        "#10\n",
        "data[:5]\n",
        "#11\n",
        "data=data.unstack().reset_index().fillna('0')\n",
        "#12\n",
        "data.set_index('InvoiceNo').head()\n",
        "#13\n",
        "data.columns=data.columns.str.replace(' ','_')\n",
        "#end"
      ],
      "metadata": {
        "id": "FtK9p1fNFO7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k-mean-clus\n",
        "import pandas as pd\n",
        "#1\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "#2\n",
        "DF = pd.read_csv('Mall_Customers.csv', encoding = 'utf-8')\n",
        "#3\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "DF_ARRAY = np.array(DF.iloc[:,2:5])         \n",
        "DF_NORM  = preprocessing.normalize(DF_ARRAY)\n",
        "#4\n",
        "import matplotlib.pyplot as plt\n",
        "Ks = range(2, 10)\n",
        "results = []\n",
        "#5\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters = 4)\n",
        "kmeans.fit(DF_NORM)\n",
        "kmeans.labels_\n",
        "DF['cluster'] = kmeans.labels_\n",
        "#6\n",
        "from sklearn.decomposition import PCA\n",
        "import pylab as pl\n",
        "PCA_ = PCA(n_components = 2).fit(DF_ARRAY)\n",
        "PCA_2 = PCA_.transform(DF_ARRAY)\n",
        "for i in range(0, PCA_2.shape[0]):\n",
        "    if kmeans.labels_[i] == 0:\n",
        "        CLUSTER_01 = pl.scatter(PCA_2[i,0], PCA_2[i,1], c ='r', marker = 'o', s = 120)\n",
        "        \n",
        "    elif kmeans.labels_[i] == 1:\n",
        "        CLUSTER_02 = pl.scatter(PCA_2[i,0], PCA_2[i,1], c ='g', marker = 'o', s = 120)\n",
        "    elif kmeans.labels_[i] == 2:\n",
        "        CLUSTER_03 = pl.scatter(PCA_2[i,0], PCA_2[i,1], c ='b', marker = 'o', s = 120)\n",
        "\n",
        "    elif kmeans.labels_[i] == 3:\n",
        "        CLUSTER_04 = pl.scatter(PCA_2[i,0], PCA_2[i,1], c ='y', marker = 'o', s = 120)\n",
        "        pl.legend([CLUSTER_01, CLUSTER_02, CLUSTER_03, CLUSTER_04],\n",
        "                  ['Cluster 01', 'Cluster 02', 'Cluster 03', 'Cluster 04'])\n",
        "        \n",
        "        pl.title('Mall Customers Categories')\n",
        "        \n",
        "pl.show()\n",
        "#7\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
        "    kmeans.fit(DF_NORM)\n",
        "    # inertia method returns wcss for that model\n",
        "    wcss.append(kmeans.inertia_)\n",
        "#8\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range(1, 11), wcss,marker='o',color='red')\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "#end\n"
      ],
      "metadata": {
        "id": "fmr8py2OFO9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensemble\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import  SVC\n",
        "#from mlxtend.classifier import StackingClassifier\n",
        "#2\n",
        "from google.colab import files\n",
        "f=files.upload()\n",
        "#3\n",
        "df=pd.read_csv(\"diabetes.csv\")\n",
        "df.head()\n",
        "#4\n",
        "x=df.drop(\"Outcome\",axis=\"columns\")\n",
        "y=df.Outcome\n",
        "y\n",
        "#5\n",
        "df.isnull()\n",
        "#6\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
        "#7\n",
        "from sklearn import tree\n",
        "#model_3=tree.DecisionTreeClassifier()\n",
        "#8\n",
        "model_1 = LogisticRegression()\n",
        "model_2 = SVC()\n",
        "model_3 = tree.DecisionTreeClassifier()\n",
        "#9\n",
        "model_1.fit(X_train, y_train)\n",
        "model_2.fit(X_train, y_train)\n",
        "model_3.fit(X_train, y_train)\n",
        "#10\n",
        "pred_1 = model_1.predict(X_test)\n",
        "pred_2 = model_2.predict(X_test)\n",
        "pred_3 = model_3.predict(X_test)\n",
        "#11\n",
        "model_1.score(X_test,y_test)\n",
        "#model_3.score(X_test,y_test)\n",
        "#12\n",
        "pred_final = (pred_1+pred_2+pred_3)/3.0\n",
        "pred_final\n",
        "#13\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "#14\n",
        "final_model = VotingClassifier(estimators=[('lr', model_1), ('svm', model_2),('dt',model_3)], voting='hard')\n",
        "#15\n",
        "final_model.fit(X_train, y_train)\n",
        "#16\n",
        "from sklearn.metrics import log_loss\n",
        "#17\n",
        "# predicting the output on the test dataset\n",
        "pred_final = final_model.predict(X_test)\n",
        "# printing log loss between actual and predicted value\n",
        "print(log_loss(y_test, pred_final))\n",
        "#18\n",
        "all_model=[model_1,model_2,model_3]\n",
        "#19\n",
        "pip install vecstack\n",
        "#20\n"
      ],
      "metadata": {
        "id": "4BmZ5lNeUVQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from skimage import io\n",
        "from PIL import Image \n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "#2\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "#3\n",
        "train_path= \"train.csv\"\n",
        "#4\n",
        "train_df = pd.read_csv(train_path)\n",
        "train_df.head()\n",
        "#5\n",
        "M_cols = train_df.columns.to_list()\n",
        "print(\"Value Distribution:\\n\")\n",
        "for col in M_cols:\n",
        "    print(col,\"\\n\",train_df[col].value_counts(),\"\\n\\n\") \n",
        "#6\n",
        "\"Data Shape (row, col): {}\".format(train_df.shape)\n",
        "#7\n",
        "train_df.info()\n",
        "#8\n",
        "train_df.isnull().sum()\n",
        "#9\n",
        "M_cols = train_df.columns.to_list()\n",
        "print(\"Value Distribution:\\n\")\n",
        "for col in M_cols:\n",
        "    print(col,\"\\n\",train_df[col].value_counts(),\"\\n\\n\")  \n",
        "#10\n",
        "for col in M_cols[1:]:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.countplot(x=col , data=train_df ,palette='icefire')\n",
        "    plt.title(col, fontsize=14)\n",
        "    plt.show()\n",
        "    print(\"% of total:\")\n",
        "    print(round((train_df[col].value_counts()/train_df.shape[0]),4)*100)\n",
        "#11\n",
        "\"Data Shape (row, col): {}\".format(train_df.shape)\n",
        "#12\n",
        "\n",
        "#13\n"
      ],
      "metadata": {
        "id": "C9WGP78RV4p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KaalNDSaFPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3k7F5zKFPDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2t74kxl0FPGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mubM-lUFPI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOECoV7DFPL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtDzzzCYFPOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQqog38RFPRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T87pN-_lFPVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOQWK6IdFPXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R_3QrO8SFPa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qeON7IsQFPdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4YbHMDvFPgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m39deWhvFPjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BH2HXAfFPmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}